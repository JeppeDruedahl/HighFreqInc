{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "colors = [x['color'] for x in plt.style.library['seaborn']['axes.prop_cycle']]\n",
    "\n",
    "import dsttools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders if necessary\n",
    "if not os.path.exists('figs'): os.makedirs('figs')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Load useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dsttools.load_datasets_disk(datafolder='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Choose settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. globals\n",
    "samples = ['p1','all'] # #  list of samples (from small to large!!!)\n",
    "class par: pass # parameters\n",
    "dfs = {} # dataframes\n",
    "tbl = dsttools.SampleSelectionTable(obs_fac=12)\n",
    "\n",
    "# b. ages\n",
    "par.age_min = 35\n",
    "par.age_max = 60\n",
    "\n",
    "# c. years\n",
    "par.bef_year = datasets['bfl']['years'][0]\n",
    "par.years = np.arange(datasets['bfl']['years'][0],datasets['bfl']['years'][-1]+1)\n",
    "par.T = par.years.size\n",
    "\n",
    "# d. selection criteria\n",
    "par.min_obs = 6         \n",
    "par.rich_cutoff = 3_000\n",
    "par.rich_cutoff_month = 500\n",
    "par.self_employed_cutoff = 20\n",
    "par.hours_cutoff = 0.95\n",
    "par.wage_cutoff = 15\n",
    "par.wage_cutoff_employed = 5   \n",
    "par.full_time_share_cutoff = 0.5\n",
    "\n",
    "# d. cohorts (implied)\n",
    "par.cohorts = [par.years[0]-(par.age_max-par.min_obs+1),par.years[-1]-(par.age_min+(par.min_obs-1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Show implications of settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'years: {par.years[0]}-{par.years[-1]}')       \n",
    "print(f'cohorts: {par.cohorts[0]}-{par.cohorts[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from **population register** and **select on sex and cohorts**. Force the dataset to be **balanced**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(sample):\n",
    "    \n",
    "    # a. load bef\n",
    "    bef = pd.read_parquet(f'data/befupd_{sample}.parquet')\n",
    "    bef = bef[bef.year == par.bef_year+1]\n",
    "        \n",
    "    # b. birthyears\n",
    "    birthyear = bef.birthday.dt.year\n",
    "    \n",
    "    # c. males and selected cohorts\n",
    "    I = (bef.sex == 1) & (birthyear.between(par.cohorts[0],par.cohorts[-1]))\n",
    "    birthyear = birthyear[I].values.astype('int')\n",
    "    male_pnr = bef[I].pnr\n",
    "    \n",
    "    # d. check pnrs are unique\n",
    "    assert male_pnr.is_unique\n",
    "    par.N = male_pnr.size\n",
    "\n",
    "    # e. create balanced dataset\n",
    "    df = pd.DataFrame({\n",
    "        'pnr':np.repeat(male_pnr,par.T),\n",
    "        'year':np.tile(par.years,par.N),\n",
    "        'birthyear':np.repeat(birthyear,par.T)\n",
    "        }).set_index(['pnr','year'])\n",
    "    \n",
    "    # f. add age\n",
    "    df['age'] = df.index.get_level_values('year')-df.birthyear\n",
    "    \n",
    "    # g. select on age\n",
    "    I = df.age.between(par.age_min,par.age_max)\n",
    "    df = df[I]\n",
    "    dfs[('raw',sample)] = df\n",
    "    \n",
    "for sample in samples:\n",
    "    %time create(sample)\n",
    "\n",
    "display(dfs[('raw',sample)].reset_index().count())\n",
    "\n",
    "tbl.add('Initial sample',dfs[('raw',sample)])\n",
    "tbl.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect balancedness:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[('raw',sample)]\n",
    "pd.crosstab(df.birthyear,df.index.get_level_values('year'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add income data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from **annual income register** (various measures) and remove individuals with multiple observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_annual_income_data(sample):\n",
    "    \n",
    "    # a. load ind\n",
    "    ind = pd.read_parquet(f'data/indupd01_{sample}.parquet')\n",
    "    ind = ind[['pnr','year','DISPON_13','PERINDKIALT_13','LOENMV_13','CORLOEN',\n",
    "               'NETOVSKUD_13','PRIVAT_PENSION_13','OFFPENS_EFTERLON_13']]\n",
    "        \n",
    "    # b. find and remove duplicates\n",
    "    ind['obs_per_year'] = ind.groupby(['pnr','year']).pnr.transform('count')\n",
    "    ind['obs_per_year'] = ind.groupby('pnr')['obs_per_year'].transform('max')\n",
    "        \n",
    "    removed = ind[ind.obs_per_year > 1].pnr.unique().size\n",
    "    print(f'Note: {removed} individuals removed due to multiple observations in a single year')\n",
    "    \n",
    "    # c. remove duplicates\n",
    "    ind = ind[ind.obs_per_year == 1]\n",
    "    ind = ind.set_index(['pnr','year'])\n",
    "    \n",
    "    # d. merge\n",
    "    dfs[('ind',sample)] = dfs[('raw',sample)].join(ind,how='left').drop('obs_per_year',axis=1)\n",
    "\n",
    "for sample in samples:\n",
    "    %time add_annual_income_data(sample)\n",
    "\n",
    "display(dfs[('ind',sample)].reset_index().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample is selected using the following **criteria**:\n",
    "\n",
    "1. Always in income register.\n",
    "2. Never self-employed - NETOVSKUD_13 never above 20,000 DKK.\n",
    "3. Never retired - never positive private (PRIVAT_PENSION_13) or public (OFFPENS_EFTERLON_13) pension.\n",
    "4. Annual wage never more than 3 million DKK.\n",
    "5. Monthly wage never more than 500,000 DKK.\n",
    "\n",
    "**Scaling:** Monetary variables are scaled with average disposable income in our data set relative to 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_select(sample):\n",
    "    \n",
    "    df = dfs[('ind',sample)]\n",
    "\n",
    "    # a. missing information\n",
    "    missing_info = df.CORLOEN.isna()\n",
    "    no_missing_info = ~(missing_info.groupby('pnr').transform('max'))\n",
    "    \n",
    "    df = df[no_missing_info]\n",
    "    tbl.add('Always in income register',df)\n",
    "\n",
    "    # b. calculate scale\n",
    "    df['scale'] = df.groupby('year').DISPON_13.transform('mean') / df.DISPON_13.xs(2018,level='year').mean()\n",
    "    \n",
    "    # c. remove self-employed\n",
    "    self_employed = df.NETOVSKUD_13 > par.self_employed_cutoff*1_000*df['scale']\n",
    "    never_self_employed = ~(self_employed.groupby('pnr').transform('max'))\n",
    "    df = df[never_self_employed]\n",
    "    tbl.add('Never self-employed',df)\n",
    "\n",
    "    # d. remove retired\n",
    "    retired = df.PRIVAT_PENSION_13 + df.OFFPENS_EFTERLON_13 > 0\n",
    "    never_retired = ~(retired.groupby('pnr').transform('max'))\n",
    "    \n",
    "    df = df[never_retired]\n",
    "    tbl.add('Never retired',df)   \n",
    "    \n",
    "    # e. clean and save\n",
    "    df = df.rename(columns={'DISPON_13':'disp_inc',\n",
    "                            'PERINDKIALT_13':'tot_inc',\n",
    "                            'LOENMV_13':'wage_tot',\n",
    "                            'CORLOEN':'wage_tot_alt'})\n",
    "    \n",
    "    df.disp_inc = df.disp_inc/1000\n",
    "    df.tot_inc = df.tot_inc/1000\n",
    "    df.wage_tot = df.wage_tot/1000\n",
    "    df.wage_tot_alt = df.wage_tot_alt/1000\n",
    "    \n",
    "    drop = ['NETOVSKUD_13','PRIVAT_PENSION_13','OFFPENS_EFTERLON_13']\n",
    "    dfs[('main_year',sample)] = df.drop(drop,axis=1)\n",
    "    \n",
    "for sample in samples:\n",
    "    %time annual_select(sample)\n",
    "    \n",
    "display(dfs[('main_year',sample)].reset_index().count())\n",
    "tbl.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the **monthly income register** (broad, narrow, hours).\n",
    "\n",
    "1. **Aggregate** to monthly level.\n",
    "2. **Add annual data**\n",
    "3. Create **balanced monthly sample**.\n",
    "\n",
    "**Note:** Hours is relative to 160.33 hours (\"full employment\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_monthly(sample):\n",
    "    \n",
    "    # a. aggregation choices\n",
    "    agg_dict = {'wage_broad':'sum','wage_narrow':'sum','hours':'sum'}\n",
    "        \n",
    "    # b. load\n",
    "    bfl = pd.read_parquet(f'data/bfl_{sample}.parquet')\n",
    "    bfl.wage_narrow = bfl.wage_narrow/1000\n",
    "    bfl.wage_broad = bfl.wage_broad/1000\n",
    "    \n",
    "    # c. aggregate to monthly\n",
    "    bfl['month'] = bfl.start_date.dt.month\n",
    "    bfl_month = bfl.groupby(['pnr','year','month']).agg(agg_dict)\n",
    "    \n",
    "    assert np.all(bfl_month[['wage_broad','wage_narrow','hours']].notna())\n",
    "    \n",
    "    # d. create balanced monthly dataset\n",
    "    pnrs = dfs[('main_year',sample)].index.unique('pnr')\n",
    "    N = pnrs.size\n",
    "\n",
    "    years = np.repeat(par.years,12)\n",
    "    months = np.tile(np.arange(1,12+1),par.T)\n",
    "    \n",
    "    dates = [f'{year}{month}' for (year,month) in zip(years,months)]\n",
    "    dates = pd.DatetimeIndex(pd.to_datetime(dates,format='%Y%m'))\n",
    "              \n",
    "    df = pd.DataFrame({'pnr':np.repeat(pnrs,par.T*12),\n",
    "                       'year':np.tile(years,N),\n",
    "                       'month':np.tile(months,N),\n",
    "                       'date':np.tile(dates,N),                       \n",
    "                      }).set_index(['pnr','year','month'])\n",
    "     \n",
    "    df = df.join(bfl_month,how='left')\n",
    "    df = df.join(dfs[('main_year',sample)][['birthyear','age','scale']],how='inner',on=['pnr','year'])\n",
    "        \n",
    "    # e. find unemployed and fill with zeros\n",
    "    df['unemployed'] = df.wage_narrow.isna() | (df.wage_narrow < par.wage_cutoff_employed*df.scale)    \n",
    "    df.loc[df.wage_narrow.isna(),['wage_broad','wage_narrow','hours']] = 0\n",
    "    \n",
    "    assert np.all(bfl_month[['wage_broad','wage_narrow','hours']].notna())\n",
    "    \n",
    "    # f. find full-time employed\n",
    "    enough_hours = df.hours > par.hours_cutoff\n",
    "    enough_wage = df.wage_narrow > par.wage_cutoff*df.scale\n",
    "    df['full_time'] = enough_hours & enough_wage\n",
    "\n",
    "    # g. save\n",
    "    dfs[('merged',sample)] = df\n",
    "    \n",
    "for sample in samples:\n",
    "    %time create_monthly(sample)\n",
    "\n",
    "display(dfs[('merged',sample)].reset_index().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Full-time and unemployment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dfs[('merged',sample)].full_time,dfs[('merged',sample)].unemployed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add monthly data to annual data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_monthly(sample):\n",
    "    \n",
    "    # a. aggregation choices\n",
    "    agg_dict = {'wage_broad':'sum',\n",
    "                'wage_narrow':'sum',\n",
    "                'hours':'sum',\n",
    "                'full_time':'mean'}\n",
    "    \n",
    "    # b. merge with annual data\n",
    "    bfl_year = dfs[('merged',sample)].groupby(['pnr','year']).agg(agg_dict)  \n",
    "    bfl_year_extra = dfs[('merged',sample)].groupby(['pnr','year']).agg({'wage_narrow':'max'}).rename(columns={'wage_narrow':'wage_narrow_max'})\n",
    "    \n",
    "    df = dfs[('main_year',sample)].join(bfl_year,how='left',on=['pnr','year']).join(bfl_year_extra,how='left',on=['pnr','year'])\n",
    "    \n",
    "    # c. drop rich - annual\n",
    "    rich = df.wage_narrow > par.rich_cutoff*df.scale\n",
    "    never_rich = ~(rich.groupby('pnr').transform('max'))\n",
    "    \n",
    "    df = df[never_rich]\n",
    "    tbl.add('Annual wage never above 3 mil. DKK',df) \n",
    "    \n",
    "    # d. drop rich - month\n",
    "    rich = df.wage_narrow_max > par.rich_cutoff_month*df.scale\n",
    "    never_rich = ~(rich.groupby('pnr').transform('max'))\n",
    "    \n",
    "    df = df[never_rich]\n",
    "    tbl.add('Monthly wage never above 500,000 DKK',df) \n",
    "    \n",
    "    # e. save\n",
    "    dfs[('merged_year',sample)] = df\n",
    "\n",
    "    # f. selected\n",
    "    df = pd.DataFrame(dfs[('merged_year',sample)].index.unique(0)).set_index('pnr')\n",
    "    dfs[('selected',sample)] = df.join(dfs[('merged',sample)])\n",
    "    \n",
    "for sample in samples:\n",
    "    %time add_monthly(sample)\n",
    "\n",
    "display(dfs[('merged_year',sample)].reset_index().count())\n",
    "display(dfs[('selected',sample)].reset_index().count())\n",
    "tbl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection on full-time employment share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[('selected',sample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram of hours:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "max_val = 1.5\n",
    "\n",
    "# a. distribution\n",
    "ax.hist(df.hours.clip(None,max_val),bins=500,cumulative=True,density=True)\n",
    "\n",
    "# b. cutoff\n",
    "ax.axvline(par.hours_cutoff,ls='--',lw=1,c='black',zorder=-1)\n",
    "\n",
    "# c. save\n",
    "ax.set_xlabel('hours relative to full-time')\n",
    "ax.set_ylabel('cdf')\n",
    "ax.set_xlim([0,max_val])\n",
    "ax.set_ylim([0,1.0])\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'figs/pre_hours_hist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram of wages for those with enough hours:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "max_val = 150\n",
    "\n",
    "# a. distribution\n",
    "x = df.wage_narrow/df.scale\n",
    "ax.hist(x[df.full_time].clip(None,max_val),bins=500,cumulative=True,density=True,label=None)\n",
    "\n",
    "# b. cutoff\n",
    "ax.axvline(par.wage_cutoff,ls='--',lw=1,c='black',zorder=-1)\n",
    "\n",
    "# c. save\n",
    "ax.set_xlabel('wage (scaled)')\n",
    "ax.set_ylabel('cdf')\n",
    "ax.set_xlim([0,max_val])\n",
    "ax.set_ylim([0,1.0])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'figs/pre_wage_hist_enough_hours.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram of full-time:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# a. distribution\n",
    "x = df.full_time.groupby('pnr').mean()\n",
    "ax.hist(x,bins=par.years.size*12,cumulative=True,density=True);\n",
    "\n",
    "# b. cutoff\n",
    "ax.axvline(par.full_time_share_cutoff,ls='--',lw=1,c='black',zorder=-1)\n",
    "\n",
    "# c. save\n",
    "ax.set_xlabel('share of months with full-time employement')\n",
    "ax.set_ylabel('cdf') \n",
    "ax.set_xlim([0,1.0])\n",
    "ax.set_ylim([0,1.0])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'figs/pre_full_time_hist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select on full-time employed in 50 percent of months**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_time_employed(sample):\n",
    "    \n",
    "    # a. load annual data\n",
    "    df = dfs[('merged_year',sample)]\n",
    "              \n",
    "    # b. select\n",
    "    keep = df.full_time.groupby('pnr').transform('mean') > par.full_time_share_cutoff    \n",
    "    keep.name = 'keep'\n",
    "    dfs[('final_year',sample)]= df[keep].drop('full_time',axis=1)\n",
    "\n",
    "    tbl.add('Full-time employed 50 percent of the time',dfs[('final_year',sample)])\n",
    "        \n",
    "    # c. load and drop monthly data\n",
    "    df = dfs[('selected',sample)].join(keep.groupby('pnr').first(),how='left',on='pnr')\n",
    "    dfs[('final',sample)] = df[df.keep].drop('keep',axis=1)\n",
    "    df = dfs[('final',sample)]\n",
    "\n",
    "for sample in samples:\n",
    "    %time full_time_employed(sample)\n",
    "\n",
    "display(dfs[('final_year',sample)].reset_index().count())\n",
    "display(dfs[('final',sample)].reset_index().count())\n",
    "    \n",
    "tbl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Share of months with full-time employment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'full-time share {dfs[(\"final\",sample)].full_time.mean():.3}')\n",
    "print(f'unemployed share {dfs[(\"final\",sample)].unemployed.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_year = dfs[('merged_year',sample)]\n",
    "display(merged_year.groupby('year').agg('mean').round(2))\n",
    "display(pd.crosstab(merged_year.birthyear,merged_year.index.get_level_values('year')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_year.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = dfs[('merged',sample)]\n",
    "display(merged.groupby('year').agg('mean').round(3))\n",
    "display(pd.crosstab(merged.birthyear,merged.index.get_level_values('year')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_year[['wage_broad','wage_narrow','wage_tot','wage_tot_alt','tot_inc','disp_inc']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. difference\n",
    "diff = merged_year.wage_narrow-merged_year.wage_tot\n",
    "abs_diff = np.abs(diff)\n",
    "rel_abs_diff = abs_diff/merged_year.wage_narrow\n",
    "\n",
    "x = np.linspace(0.5,1.00,51)\n",
    "\n",
    "# b. differences\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "diff_cap = np.clip(diff,-100,100)\n",
    "ax.hist(diff_cap,bins=500,density=True,cumulative=True)\n",
    "ax.set_xlabel('DKK')\n",
    "ax.set_ylabel('cdf')\n",
    "ax.set_title('differences')\n",
    "\n",
    "# b. absolute differences\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "y = abs_diff.quantile(x)\n",
    "ax.plot(x[:-2],y.values[:-2])\n",
    "ax.set_xlabel('percentile')\n",
    "ax.set_ylabel('DKK')\n",
    "ax.set_title('absolute difference')\n",
    "\n",
    "# c. relative absolute differences\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "y_all = rel_abs_diff.quantile(x)\n",
    "ax.plot(x[:-2],y_all.values[:-2],label='all')\n",
    "\n",
    "I = merged_year.wage_narrow > 10*merged_year.scale \n",
    "y_sel = rel_abs_diff[I].quantile(x)\n",
    "ax.plot(x[:-2],y_sel.values[:-2],label='wage > 10,000')\n",
    "\n",
    "ax.set_xlabel('percentile')\n",
    "ax.set_ylabel('percent')\n",
    "ax.set_title('relative absolute difference')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. difference by year\n",
    "diff = merged_year.wage_narrow-merged_year.wage_tot\n",
    "abs_diff = np.abs(diff)\n",
    "rel_abs_diff = abs_diff/merged_year.wage_narrow\n",
    "\n",
    "# b. quantiles by year\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "x = np.linspace(0.7,0.98,51)\n",
    "ys = rel_abs_diff.groupby(['year']).quantile(x)\n",
    "\n",
    "for year in [2011,2017,2018]:\n",
    "    y = ys.xs(year,level='year')\n",
    "    ax.plot(x,y,label=str(year))\n",
    "\n",
    "ax.set_xlabel('percentile')\n",
    "ax.set_ylabel('percent')\n",
    "ax.set_title('relative absolute difference')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Varying cutoffs in DKK and percent:**\n",
    "\n",
    "1. **ok:** Discrepancy less than DKK cutoff *or* less than percent cutoff.\n",
    "2. **keep:** Always ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for abs_diff_cut in [5,10,20,30,40,50]:\n",
    "    for rel_abs_diff_cut in [0.025,0.05,0.075,0.10,np.inf]:\n",
    "        \n",
    "        ok_or = (abs_diff < abs_diff_cut) | (rel_abs_diff < rel_abs_diff_cut)\n",
    "        ok_and = (abs_diff < abs_diff_cut) & (rel_abs_diff < rel_abs_diff_cut)\n",
    "        keep = ok_or.groupby('pnr').transform('min')\n",
    "        \n",
    "        row = {'DKK':[abs_diff_cut],\n",
    "               'percent':[rel_abs_diff_cut],\n",
    "               'ok_or':[ok_or.mean()],\n",
    "               'ok_and':[ok_and.mean()],\n",
    "               'keep':[keep.mean()]}\n",
    "        df = df.append(pd.DataFrame(row))\n",
    "        \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    %time dfs[('final_year',sample)].to_parquet(f'data/final_year_{sample}.parquet')\n",
    "    %time dfs[('final',sample)].to_parquet(f'data/final_{sample}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write sample selection table in Latex:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.show()\n",
    "tbl.latex('figs/sample_selection.tex')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
